{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KvrRl029pPB"
      },
      "source": [
        "<img src=\"https://i.ibb.co/qjt4Ymb/2022-09-19-004719.png\" alt=\"2022-09-19-004719\" border=\"0\">\n",
        "\n",
        "# Topic 17: AOI-Automated Optical Inspection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhFS0k6edj4s"
      },
      "source": [
        "# AIdea AOI Project\n",
        "* This tutorial uses the AOI dataset of the AIdea platform.\n",
        "* Introduce how to write deep learning programs to classify defects in automatic optical inspection.\n",
        "* This notebook program can be executed in the cloud using Google Colab or Jupyter on a personal computer.\n",
        "\n",
        "AIdea AOI Project\n",
        "https://aidea-web.tw/topic/285ef3be-44eb-43dd-85cc-f0388bf85ea4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkguTuu0doDW"
      },
      "source": [
        "# (A) AIdea dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMzNhOKcFJTV"
      },
      "source": [
        "## Step 1: Load the AIdea AOI dataset from google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gdown https://drive.google.com/uc?id=1tovCO2gsjesjJ8OsfHgahyt-buY34dk0\n",
        "unzip aoi-dataset.zip\n",
        "rm aoi-dataset.zip"
      ],
      "metadata": {
        "id": "A7IQ_8FNqt9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR_KADlQk7Gs"
      },
      "source": [
        "## Step 2: read the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaFX5Cqgicw0"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "print(df_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dwc7F7dioM7"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHjI9HpmRfac"
      },
      "source": [
        "## Step 3: Build the lists of training images and labels from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LizhcbfXis75"
      },
      "source": [
        "#limit the amount of training images for the class process\n",
        "#train_num = 480\n",
        "train_num = df_train.shape[0]\n",
        "if train_num >= df_train.shape[0]:\n",
        "  train_num = df_train.shape[0]\n",
        "train_files = df_train.iloc[:train_num,0].values\n",
        "train_labels = df_train.iloc[:train_num,1].values\n",
        "print(train_labels[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uImM5L4DlG4X"
      },
      "source": [
        "## Step 4: read images of the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2GH166li2f6"
      },
      "source": [
        "train_path =\"train_images/\"\n",
        "train_images = []\n",
        "from tensorflow.keras.preprocessing import image\n",
        "for file in train_files:\n",
        "    img = image.load_img(train_path+file, color_mode=\"rgb\", target_size = (299, 299))\n",
        "    train_images.append(img)\n",
        "    if len(train_images)%100 == 0:\n",
        "      print('.', end='')\n",
        "print(len(train_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQAGGlik5Gz"
      },
      "source": [
        "## Step 5: show AOI images of the classes:\n",
        "0 (normal), 1 (void), 2 (horizontal  defect) 3 (vertical defect), 4 (edge defect), 5 (particle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqB5T0_yk21r"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xBuhRnLlmTM"
      },
      "source": [
        "import random\n",
        "curclass = 0\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        curclass += 1\n",
        "        curclass %= 6\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA2AWBT09Klk"
      },
      "source": [
        "# Class 0-normal\n",
        "import random\n",
        "curclass = 0\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvcrqsuM9Zof"
      },
      "source": [
        "# Class 1-void\n",
        "import random\n",
        "curclass = 1\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttimxvzo9mgs"
      },
      "source": [
        "# Class 2-horizontal defect\n",
        "import random\n",
        "curclass = 2\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xRwCCZt9vyS"
      },
      "source": [
        "# Class 3-vertical defect\n",
        "import random\n",
        "curclass = 3\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avZBx0Lq9ymv"
      },
      "source": [
        "# Class 4-edge defect\n",
        "import random\n",
        "curclass = 4\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrLNwULy90IJ"
      },
      "source": [
        "# Class 5-particle\n",
        "import random\n",
        "curclass = 5\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMxY9IGumAew"
      },
      "source": [
        "## Step 6: Show statistics of training images in the 6 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGZkuGS3mTCO"
      },
      "source": [
        "import numpy as np\n",
        "labels, counts = np.unique(train_labels, return_counts=True)\n",
        "print(labels, counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTX_Anx0mWzQ"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, counts, width=0.7, align='center')\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(labels)\n",
        "plt.ylim(0, 680)\n",
        "\n",
        "for a, b in zip(labels, counts):\n",
        "    plt.text(a, b, '%d' % b, ha='center', va='bottom', fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD4ZBffHX71W"
      },
      "source": [
        "# (B) TensorFlow 2.0 Keras applications with ImageNet models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c20jGAYlcW5j"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQtcWITNcMHK"
      },
      "source": [
        "## Step 7: Keras Applications Models\n",
        "<img src=\"https://miro.medium.com/max/1571/1*XB4SlSGxGKFQbIBoil0aDg.png\" alt=\"Pre-train models\" width=\"500\">\n",
        "\n",
        "Pre-train models of tf.Keras includes Xception、VGG16、VGG19、ResNet50、InceptionV3、InceptionResNetV2、MobileNet、DenseNet、NASNet、MobileNetV2\n",
        "<img src=\"https://miro.medium.com/max/1280/0*L8egayRvFZOAmvqc.png\" alt=\"Pre-train models\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxLyEiuFEIgI"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "model = InceptionV3(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpyO_On4Egdx"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "model = Xception(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su_yDmG6EkkX"
      },
      "source": [
        "from tensorflow.keras.applications import NASNetLarge\n",
        "from tensorflow.keras.applications.nasnet import preprocess_input\n",
        "model = NASNetLarge(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh36dHu0EtH_"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
        "model = InceptionResNetV2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ8_jQYQExo3"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "model = MobileNetV2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WZxmhSPE4D8"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "model = ResNet50V2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCVO6g04GFMi"
      },
      "source": [
        "## Step 8: Keras Applications preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZzsTx4cHrze"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "x = image.img_to_array(train_images[0])\n",
        "img_array = preprocess_input(x, mode = 'tf' )\n",
        "print(img_array[0 , 0 , 0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaW40jTcIh0g"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "x = image.img_to_array(train_images[0])\n",
        "img_array = preprocess_input(x, mode = 'torch' )\n",
        "print(img_array[0 , 0 , 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkwlHXQunZ02"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "x = image.img_to_array(train_images[0])\n",
        "img_array = preprocess_input(x, mode = 'caffe' )\n",
        "print(img_array[0 , 0 , 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDkl3H-woXKA"
      },
      "source": [
        "## Step 9: Tranfer learning\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1000/1*frBNwuPg0kUsWFqfBlvxLg.png\" alt=\"Pre-train models\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y-15yJXn_LM"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSObvzWmofw_"
      },
      "source": [
        "#the InceptionV3 model\n",
        "num_classes = 6\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "base_model = InceptionV3(include_top = False, input_shape=(299,299,3), weights='imagenet', classes=num_classes)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9FohfRfmRs"
      },
      "source": [
        "base_model.trainable = False\n",
        "last_layer = base_model.output\n",
        "last_layer=Flatten()(last_layer)\n",
        "last_layer=Dropout(0.3)(last_layer)\n",
        "out = Dense(num_classes, activation='softmax', name='softmax')(last_layer)\n",
        "custom_model = Model(base_model.input, out)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}